{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8beebae-b8ab-4859-9269-0b3bfb88efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 22:25:44 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.58.02              Driver Version: 555.58.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P0             17W /   80W |      44MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       789      G   /usr/lib/Xorg                                   4MiB |\n",
      "|    0   N/A  N/A     11370      G   /usr/bin/vlc                                   28MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Python 3.8.19\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb71b578-c8f4-4c24-a772-3d2c9bcfd608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of characters in the text file : 41241\n",
      "Character Set : \n",
      "{'W', 'g', 'U', 'p', ',', '5', 'D', 'v', 'a', '-', 'q', 'J', '*', ' ', 'b', 'E', 'Q', 'c', 'N', 'e', 's', 'L', 'K', '\"', 'h', 'I', 'S', 'P', 'r', 'm', 'T', '.', ']', 'G', 'F', '_', 'V', 'B', 'x', 'j', '[', 'A', '\\n', 'u', '1', 'k', 'Y', 'z', 'y', ';', 'w', 'n', 'O', '?', 'i', 'C', '9', 't', 'd', ':', 'o', '4', 'R', 'l', \"'\", 'M', '2', 'H', 'f', '!'}\n",
      "Total distinct characters : 70\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(f\"Total no. of characters in the text file : {len(text)}\")\n",
    "\n",
    "characters = set(text)\n",
    "print(\"Character Set : \")\n",
    "print(characters)\n",
    "print(f\"Total distinct characters : {len(characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba31c154-cda6-4c17-bb50-02214f61bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to Integer set : \n",
      "{'W': 0, 'g': 1, 'U': 2, 'p': 3, ',': 4, '5': 5, 'D': 6, 'v': 7, 'a': 8, '-': 9, 'q': 10, 'J': 11, '*': 12, ' ': 13, 'b': 14, 'E': 15, 'Q': 16, 'c': 17, 'N': 18, 'e': 19, 's': 20, 'L': 21, 'K': 22, '\"': 23, 'h': 24, 'I': 25, 'S': 26, 'P': 27, 'r': 28, 'm': 29, 'T': 30, '.': 31, ']': 32, 'G': 33, 'F': 34, '_': 35, 'V': 36, 'B': 37, 'x': 38, 'j': 39, '[': 40, 'A': 41, '\\n': 42, 'u': 43, '1': 44, 'k': 45, 'Y': 46, 'z': 47, 'y': 48, ';': 49, 'w': 50, 'n': 51, 'O': 52, '?': 53, 'i': 54, 'C': 55, '9': 56, 't': 57, 'd': 58, ':': 59, 'o': 60, '4': 61, 'R': 62, 'l': 63, \"'\": 64, 'M': 65, '2': 66, 'H': 67, 'f': 68, '!': 69}\n",
      "Integer to String set : \n",
      "{0: 'W', 1: 'g', 2: 'U', 3: 'p', 4: ',', 5: '5', 6: 'D', 7: 'v', 8: 'a', 9: '-', 10: 'q', 11: 'J', 12: '*', 13: ' ', 14: 'b', 15: 'E', 16: 'Q', 17: 'c', 18: 'N', 19: 'e', 20: 's', 21: 'L', 22: 'K', 23: '\"', 24: 'h', 25: 'I', 26: 'S', 27: 'P', 28: 'r', 29: 'm', 30: 'T', 31: '.', 32: ']', 33: 'G', 34: 'F', 35: '_', 36: 'V', 37: 'B', 38: 'x', 39: 'j', 40: '[', 41: 'A', 42: '\\n', 43: 'u', 44: '1', 45: 'k', 46: 'Y', 47: 'z', 48: 'y', 49: ';', 50: 'w', 51: 'n', 52: 'O', 53: '?', 54: 'i', 55: 'C', 56: '9', 57: 't', 58: 'd', 59: ':', 60: 'o', 61: '4', 62: 'R', 63: 'l', 64: \"'\", 65: 'M', 66: '2', 67: 'H', 68: 'f', 69: '!'}\n",
      "Encoded information : [41, 45, 54, 63, 19, 20, 24] \n",
      "Decoded information : Akilesh \n"
     ]
    }
   ],
   "source": [
    "# Designing the tokenizer\n",
    "# source : https://huggingface.co/docs/transformers/en/main_classes/tokenizer\n",
    "\n",
    "# Character tokenizer\n",
    "str_to_int = { char:ind for ind, char in enumerate(characters) }\n",
    "print(\"String to Integer set : \")\n",
    "print(str_to_int)\n",
    "\n",
    "int_to_str = { ind:char for ind, char in enumerate(characters) }\n",
    "print(\"Integer to String set : \")\n",
    "print(int_to_str)\n",
    "\n",
    "# Defining the encoder\n",
    "def encoder(word):\n",
    "    return [ str_to_int[char] for char in word ]\n",
    "\n",
    "def decoder(lst):\n",
    "    return ''.join([ int_to_str[i] for i in lst ])\n",
    "\n",
    "\n",
    "encoded = encoder(\"Akilesh\")\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "print(f\"Encoded information : {encoded} \")\n",
    "print(f\"Decoded information : {decoded} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2984096-a595-4311-a498-356fbc44983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcdc63f-b26c-4f54-b3bf-9c9f8ccb3080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13, 13,  ..., 48, 31, 42])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling larger data with tensors\n",
    "encoded_text = torch.tensor(encoder(text), dtype=torch.long)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327d2df5-c5bb-4da9-98f1-d116050a0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set : tensor([13, 13, 13,  ...,  8, 28, 58])\n",
      "Test set : tensor([31, 42, 42,  ..., 48, 31, 42])\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training and testing dataset ( 80:20 ratio )\n",
    "n = int(0.8*len(text))\n",
    "train_set = encoded_text[:n]\n",
    "test_set = encoded_text[n:]\n",
    "\n",
    "print(f\"Train set : {train_set}\")\n",
    "print(f\"Test set : {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fff098f-f829-47f8-937e-8d5245570b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the constants\n",
    "BLOCK_SIZE = 18\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0d649d-f54f-4f10-a924-023ea6bc8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Input context -> tensor([13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n",
      "For the Input context -> tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]), the target value -> 13\n"
     ]
    }
   ],
   "source": [
    "# Splitting the encoded data into bigrams\n",
    "x = train_set[:BLOCK_SIZE]\n",
    "y = train_set[1:BLOCK_SIZE+1]\n",
    "\n",
    "for t in range(BLOCK_SIZE):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"For the Input context -> {context}, the target value -> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7211cf7-2aee-4571-b5fc-70577de8afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 67, 19, 13,  0, 24, 60, 13,\n",
      "        26, 19, 28,  7])\n"
     ]
    }
   ],
   "source": [
    "# Verifying the train_set\n",
    "print(train_set[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d28299a-c0c2-4770-ad95-cd45c72a8fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the availability of the devices\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f725702-784d-47ed-882c-2deaafd750a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparing the performance between CPU and GPU\n",
    "shape = (100, 100, 100)\n",
    "\n",
    "# Loading the tensor in the GPU\n",
    "gpu_tensor_1 = torch.rand(shape).to(device)\n",
    "gpu_tensor_2 = torch.rand(shape).to(device)\n",
    "\n",
    "# Loading a tensor in the CPU using CPU\n",
    "cpu_tensor_1 = np.random.rand(100, 100, 100)\n",
    "cpu_tensor_2 = np.random.rand(100, 100, 100)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f34b1e3-5605-4547-b297-33d49b6f7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by GPU : 0.04595470428466797\n",
      "CPU times: user 29.3 ms, sys: 14.4 ms, total: 43.7 ms\n",
      "Wall time: 46.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluating the time for the GPU operation\n",
    "start_time = time.time()\n",
    "gpu_result = gpu_tensor_1 @ gpu_tensor_2\n",
    "end_time = time.time()\n",
    "\n",
    "gpu_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken by GPU : {gpu_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f067f07-82d5-47d7-9e1f-5abe6f840db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by CPU : 5.92145299911499\n",
      "CPU times: user 5.21 s, sys: 702 ms, total: 5.91 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluating the time for the CPU opearation\n",
    "start_time = time.time()\n",
    "cpu_result = cpu_tensor_1.dot(cpu_tensor_2)\n",
    "end_time = time.time()\n",
    "\n",
    "cpu_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken by CPU : {cpu_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f853a2-5bc8-4697-81f0-ad94c8f3dba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upper triangular matrix\n",
    "torch.triu(torch.ones((5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46f0be9e-4eb4-4c63-954e-0f2206db9c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked tensors : \n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [inf, 0., 0., 0., 0.],\n",
      "        [inf, inf, 0., 0., 0.],\n",
      "        [inf, inf, inf, 0., 0.],\n",
      "        [inf, inf, inf, inf, 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Masked fill function in PyTorch tensor\n",
    "masked_out = torch.zeros((5, 5)).masked_fill(torch.triu(torch.ones((5, 5))) == 0, float('inf'))\n",
    "print(\"Masked tensors : \")\n",
    "print(masked_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae4ef501-8a26-4996-b5c9-e23244b2d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer instances : Linear(in_features=10, out_features=10, bias=True)\n",
      "Layer weight : \n",
      "Parameter containing:\n",
      "tensor([[-0.2891,  0.0110, -0.1532, -0.0784,  0.0460, -0.1411, -0.0891, -0.1020,\n",
      "         -0.1600,  0.1876],\n",
      "        [ 0.2810, -0.2462, -0.3046,  0.2006,  0.1112,  0.3092,  0.1315,  0.1318,\n",
      "         -0.2010, -0.1233],\n",
      "        [-0.1596, -0.3042,  0.2773,  0.0317,  0.3156, -0.0209, -0.0972,  0.0848,\n",
      "         -0.2068, -0.3118],\n",
      "        [-0.0726,  0.2966, -0.0307,  0.2418, -0.3014,  0.0796, -0.2393, -0.2154,\n",
      "         -0.1649, -0.0529],\n",
      "        [-0.1402, -0.3020, -0.0155, -0.2382,  0.2940, -0.2861,  0.2059, -0.0497,\n",
      "          0.0451,  0.2967],\n",
      "        [ 0.0953,  0.2637,  0.2004, -0.2375, -0.1823,  0.2173, -0.1855, -0.0125,\n",
      "         -0.2493, -0.2728],\n",
      "        [ 0.1997,  0.2051,  0.2904,  0.1485,  0.1018,  0.2292,  0.0184,  0.0171,\n",
      "          0.0578,  0.2521],\n",
      "        [ 0.2066,  0.2605, -0.1517,  0.2145,  0.1337, -0.2377, -0.1766, -0.1730,\n",
      "         -0.0411,  0.0947],\n",
      "        [-0.1103,  0.1716, -0.0697,  0.1382,  0.1602,  0.3024,  0.1247, -0.0687,\n",
      "         -0.1109, -0.2606],\n",
      "        [ 0.0385,  0.0803,  0.0760, -0.2011,  0.2233,  0.1496,  0.1183, -0.2839,\n",
      "          0.0452, -0.2480]], requires_grad=True)\n",
      "Layer bias : \n",
      "Parameter containing:\n",
      "tensor([-0.2376,  0.1875,  0.1390, -0.0870, -0.0706, -0.0380, -0.0440, -0.0034,\n",
      "        -0.2943, -0.2517], requires_grad=True)\n",
      "Input tensors : \n",
      "tensor([[0.9308, 0.6305, 0.5642, 0.5806, 0.8398, 0.7099, 0.6701, 0.5556, 0.5236,\n",
      "         0.3522]])\n",
      "Output tensors : \n",
      "tensor([[-0.8274,  0.5639, -0.0123, -0.4261, -0.2562, -0.1645,  0.9104,  0.1331,\n",
      "         -0.0031, -0.0875]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of torch.nn.Linear module\n",
    "\n",
    "from torch.nn import Linear\n",
    "\n",
    "# Initialising the Linear module \n",
    "# Perform the operations -> y = xA^T + b\n",
    "linear_layer = Linear(10, 10, bias=True)\n",
    "print(f\"Linear layer instances : {linear_layer}\")\n",
    "\n",
    "# Checking the initial weight and bias\n",
    "print(\"Layer weight : \")\n",
    "print(linear_layer.weight)\n",
    "print(\"Layer bias : \")\n",
    "print(linear_layer.bias)\n",
    "\n",
    "# multiply the mat1(1x10) and mat2(10x10)\n",
    "in_tensor = torch.rand((1, 10))\n",
    "print(\"Input tensors : \")\n",
    "print(in_tensor)\n",
    "\n",
    "out_tensor = linear_layer(in_tensor)\n",
    "print(\"Output tensors : \")\n",
    "print(out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4c64890-fb59-4d70-8ec0-14fe99798ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensors : tensor([0., 1., 2., 3., 4.])\n",
      "Output tensor : tensor([0.0117, 0.0317, 0.0861, 0.2341, 0.6364])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "input_tensor = torch.arange(5, dtype=torch.float)\n",
    "print(f\"Input tensors : {input_tensor}\")\n",
    "# print(input_tensor.dtype)\n",
    "\n",
    "# Performing the softmax function\n",
    "softmax_output = F.softmax(input_tensor, dim=0)\n",
    "print(f\"Output tensor : {softmax_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18871623-5723-49f0-b60c-3c3737d1e765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
