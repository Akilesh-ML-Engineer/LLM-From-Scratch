{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8beebae-b8ab-4859-9269-0b3bfb88efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 16:47:30 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.58.02              Driver Version: 555.58.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P0             16W /   80W |      13MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       794      G   /usr/lib/Xorg                                   4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Python 3.8.19\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb71b578-c8f4-4c24-a772-3d2c9bcfd608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of characters in the text file : 41241\n",
      "Character Set : \n",
      "{'.', 'c', '1', 'b', '4', 'V', '\\n', '9', '?', 'k', '_', '!', 'z', 'q', 'f', 'e', 'C', 'a', 't', 'Y', 'U', 'O', \"'\", 'w', '5', 'Q', 'B', 'A', 'M', 'K', 'i', 'H', ';', 'P', 'n', 'T', ']', 'F', 'R', ',', 'p', '*', 'v', 'r', 'u', '-', 'L', 'D', 'E', 'J', 'I', '[', 's', 'x', ':', 'S', 'N', 'h', ' ', 'd', 'y', 'l', 'W', 'j', 'G', '2', '\"', 'm', 'o', 'g'}\n",
      "Total distinct characters : 70\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(f\"Total no. of characters in the text file : {len(text)}\")\n",
    "\n",
    "characters = set(text)\n",
    "print(\"Character Set : \")\n",
    "print(characters)\n",
    "print(f\"Total distinct characters : {len(characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba31c154-cda6-4c17-bb50-02214f61bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to Integer set : \n",
      "{'.': 0, 'c': 1, '1': 2, 'b': 3, '4': 4, 'V': 5, '\\n': 6, '9': 7, '?': 8, 'k': 9, '_': 10, '!': 11, 'z': 12, 'q': 13, 'f': 14, 'e': 15, 'C': 16, 'a': 17, 't': 18, 'Y': 19, 'U': 20, 'O': 21, \"'\": 22, 'w': 23, '5': 24, 'Q': 25, 'B': 26, 'A': 27, 'M': 28, 'K': 29, 'i': 30, 'H': 31, ';': 32, 'P': 33, 'n': 34, 'T': 35, ']': 36, 'F': 37, 'R': 38, ',': 39, 'p': 40, '*': 41, 'v': 42, 'r': 43, 'u': 44, '-': 45, 'L': 46, 'D': 47, 'E': 48, 'J': 49, 'I': 50, '[': 51, 's': 52, 'x': 53, ':': 54, 'S': 55, 'N': 56, 'h': 57, ' ': 58, 'd': 59, 'y': 60, 'l': 61, 'W': 62, 'j': 63, 'G': 64, '2': 65, '\"': 66, 'm': 67, 'o': 68, 'g': 69}\n",
      "Integer to String set : \n",
      "{0: '.', 1: 'c', 2: '1', 3: 'b', 4: '4', 5: 'V', 6: '\\n', 7: '9', 8: '?', 9: 'k', 10: '_', 11: '!', 12: 'z', 13: 'q', 14: 'f', 15: 'e', 16: 'C', 17: 'a', 18: 't', 19: 'Y', 20: 'U', 21: 'O', 22: \"'\", 23: 'w', 24: '5', 25: 'Q', 26: 'B', 27: 'A', 28: 'M', 29: 'K', 30: 'i', 31: 'H', 32: ';', 33: 'P', 34: 'n', 35: 'T', 36: ']', 37: 'F', 38: 'R', 39: ',', 40: 'p', 41: '*', 42: 'v', 43: 'r', 44: 'u', 45: '-', 46: 'L', 47: 'D', 48: 'E', 49: 'J', 50: 'I', 51: '[', 52: 's', 53: 'x', 54: ':', 55: 'S', 56: 'N', 57: 'h', 58: ' ', 59: 'd', 60: 'y', 61: 'l', 62: 'W', 63: 'j', 64: 'G', 65: '2', 66: '\"', 67: 'm', 68: 'o', 69: 'g'}\n",
      "Encoded information : [27, 9, 30, 61, 15, 52, 57] \n",
      "Decoded information : Akilesh \n"
     ]
    }
   ],
   "source": [
    "# Designing the tokenizer\n",
    "# source : https://huggingface.co/docs/transformers/en/main_classes/tokenizer\n",
    "\n",
    "# Character tokenizer\n",
    "str_to_int = { char:ind for ind, char in enumerate(characters) }\n",
    "print(\"String to Integer set : \")\n",
    "print(str_to_int)\n",
    "\n",
    "int_to_str = { ind:char for ind, char in enumerate(characters) }\n",
    "print(\"Integer to String set : \")\n",
    "print(int_to_str)\n",
    "\n",
    "# Defining the encoder\n",
    "def encoder(word):\n",
    "    return [ str_to_int[char] for char in word ]\n",
    "\n",
    "def decoder(lst):\n",
    "    return ''.join([ int_to_str[i] for i in lst ])\n",
    "\n",
    "\n",
    "encoded = encoder(\"Akilesh\")\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "print(f\"Encoded information : {encoded} \")\n",
    "print(f\"Decoded information : {decoded} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2984096-a595-4311-a498-356fbc44983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fcdc63f-b26c-4f54-b3bf-9c9f8ccb3080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58, 58, 58,  ..., 60,  0,  6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling larger data with tensors\n",
    "encoded_text = torch.tensor(encoder(text), dtype=torch.long)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327d2df5-c5bb-4da9-98f1-d116050a0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set : tensor([58, 58, 58,  ..., 17, 43, 59])\n",
      "Test set : tensor([ 0,  6,  6,  ..., 60,  0,  6])\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training and testing dataset ( 80:20 ratio )\n",
    "n = int(0.8*len(text))\n",
    "train_set = encoded_text[:n]\n",
    "test_set = encoded_text[n:]\n",
    "\n",
    "print(f\"Train set : {train_set}\")\n",
    "print(f\"Test set : {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fff098f-f829-47f8-937e-8d5245570b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the constants\n",
    "BLOCK_SIZE = 18\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0d649d-f54f-4f10-a924-023ea6bc8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Input context -> tensor([58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n",
      "For the Input context -> tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58]), the target value -> 58\n"
     ]
    }
   ],
   "source": [
    "# Splitting the encoded data into bigrams\n",
    "x = train_set[:BLOCK_SIZE]\n",
    "y = train_set[1:BLOCK_SIZE+1]\n",
    "\n",
    "for t in range(BLOCK_SIZE):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"For the Input context -> {context}, the target value -> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7211cf7-2aee-4571-b5fc-70577de8afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
      "        58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 31, 15, 58, 62, 57, 68, 58,\n",
      "        55, 15, 43, 42])\n"
     ]
    }
   ],
   "source": [
    "# Verifying the train_set\n",
    "print(train_set[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d28299a-c0c2-4770-ad95-cd45c72a8fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the availability of the devices\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f725702-784d-47ed-882c-2deaafd750a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparing the performance between CPU and GPU\n",
    "shape = (100, 100, 100)\n",
    "\n",
    "# Loading the tensor in the GPU\n",
    "gpu_tensor_1 = torch.rand(shape).to(device)\n",
    "gpu_tensor_2 = torch.rand(shape).to(device)\n",
    "\n",
    "# Loading a tensor in the CPU using CPU\n",
    "cpu_tensor_1 = np.random.rand(100, 100, 100)\n",
    "cpu_tensor_2 = np.random.rand(100, 100, 100)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f34b1e3-5605-4547-b297-33d49b6f7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by GPU : 0.04956936836242676\n",
      "CPU times: user 14 ms, sys: 32.9 ms, total: 46.9 ms\n",
      "Wall time: 49.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluating the time for the GPU operation\n",
    "start_time = time.time()\n",
    "gpu_result = gpu_tensor_1 @ gpu_tensor_2\n",
    "end_time = time.time()\n",
    "\n",
    "gpu_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken by GPU : {gpu_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f067f07-82d5-47d7-9e1f-5abe6f840db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by CPU : 5.0816285610198975\n",
      "CPU times: user 4.85 s, sys: 220 ms, total: 5.07 s\n",
      "Wall time: 5.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluating the time for the CPU opearation\n",
    "start_time = time.time()\n",
    "cpu_result = cpu_tensor_1.dot(cpu_tensor_2)\n",
    "end_time = time.time()\n",
    "\n",
    "cpu_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken by CPU : {cpu_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f0be9e-4eb4-4c63-954e-0f2206db9c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked tensors : \n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [inf, 0., 0., 0., 0.],\n",
      "        [inf, inf, 0., 0., 0.],\n",
      "        [inf, inf, inf, 0., 0.],\n",
      "        [inf, inf, inf, inf, 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Masked fill function in PyTorch tensor\n",
    "masked_out = torch.zeros((5, 5)).masked_fill(torch.triu(torch.ones((5, 5))) == 0, float('inf'))\n",
    "print(\"Masked tensors : \")\n",
    "print(masked_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae4ef501-8a26-4996-b5c9-e23244b2d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer instances : Linear(in_features=10, out_features=10, bias=False)\n",
      "Initial weight : \n",
      "Parameter containing:\n",
      "tensor([[ 0.0190,  0.1485, -0.2902,  0.1924, -0.0275,  0.2078,  0.2534, -0.1120,\n",
      "         -0.1297, -0.1313],\n",
      "        [ 0.2927, -0.0912, -0.0653, -0.0087,  0.0990,  0.1928,  0.1312, -0.1907,\n",
      "          0.2208, -0.0170],\n",
      "        [ 0.1072,  0.2369, -0.0004, -0.1037, -0.2781, -0.1441,  0.0343, -0.1972,\n",
      "          0.0558, -0.2881],\n",
      "        [-0.0588,  0.0541, -0.2708,  0.2119,  0.1381, -0.0037, -0.1540,  0.1196,\n",
      "         -0.0901, -0.1160],\n",
      "        [ 0.1128,  0.2377,  0.2327,  0.2894, -0.2680,  0.1812, -0.3088, -0.1544,\n",
      "         -0.2978,  0.0228],\n",
      "        [-0.1779,  0.2228, -0.1863,  0.0325,  0.1078, -0.2185, -0.2857,  0.2137,\n",
      "          0.3151,  0.1123],\n",
      "        [-0.2007,  0.1843,  0.1605, -0.0117,  0.0172, -0.2916, -0.0191, -0.2422,\n",
      "         -0.1637, -0.1020],\n",
      "        [-0.1472,  0.2095,  0.2829, -0.1924,  0.0795, -0.1742,  0.2037, -0.1400,\n",
      "          0.1254, -0.0831],\n",
      "        [-0.2921, -0.0766, -0.0332,  0.0471,  0.2368,  0.0585,  0.1134, -0.1093,\n",
      "         -0.0808,  0.2945],\n",
      "        [ 0.0211, -0.0177, -0.3109, -0.2950,  0.3053, -0.0304,  0.0500, -0.1493,\n",
      "          0.1999,  0.1674]], requires_grad=True)\n",
      "Initial bias : \n",
      "None\n",
      "Input tensors : \n",
      "tensor([[0.9857, 0.9368, 0.0500, 0.7140, 0.7848, 0.1711, 0.1688, 0.4009, 0.5798,\n",
      "         0.2157]])\n",
      "Output tensors : \n",
      "tensor([[ 0.1890,  0.3744, -0.0924,  0.1829,  0.0911,  0.3389, -0.2791, -0.0065,\n",
      "         -0.1399,  0.1131]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of torch.nn.Linear module\n",
    "\n",
    "from torch.nn import Linear\n",
    "\n",
    "# Initialising the Linear module \n",
    "# Perform the operations -> y = xA^T + b\n",
    "linear_layer = Linear(10, 10, bias=True/)\n",
    "print(f\"Linear layer instances : {linear_layer}\")\n",
    "\n",
    "# Checking the initial weight and bias\n",
    "print(\"Initial weight : \")\n",
    "print(linear_layer.weight)\n",
    "print(\"Initial bias : \")\n",
    "print(linear_layer.bias)\n",
    "\n",
    "# multiply the mat1(1x10) and mat2(10x10)\n",
    "in_tensor = torch.rand((1, 10))\n",
    "print(\"Input tensors : \")\n",
    "print(in_tensor)\n",
    "\n",
    "out_tensor = linear_layer(in_tensor)\n",
    "print(\"Output tensors : \")\n",
    "print(out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d7a31-312f-4060-b673-045908975089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
